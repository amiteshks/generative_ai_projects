{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f95de6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key is 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\n"
     ]
    }
   ],
   "source": [
    "# pip install langchain_openai langchain_core langgraph python-dotenv openai\n",
    "# pip install -U langgraph \"langchain[openai]\"\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langsmith import traceable\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print (f'Key is {my_api_key}')\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=my_api_key)\n",
    "\n",
    "\n",
    "# --- Shared State ---\n",
    "class LibraryState(TypedDict):\n",
    "    question: str\n",
    "    faq_answer: str\n",
    "    checkout_info: str\n",
    "    final_answer: str\n",
    "\n",
    "@traceable(name=\"ClassifierAgent\")\n",
    "def ClassifierAgent(state: LibraryState):\n",
    "    print(\"ClassifierAgent ran\")\n",
    "    print(f\"state: {state}\")\n",
    "\n",
    "    # Build the LLM messages\n",
    "    message_to_llm = [\n",
    "        {\"role\": \"system\", \"content\": '''You are a classifier agent in a library system. Decide if the user is asking about book availability/checkout or about library FAQs. \n",
    "        Reply with JSON containing keys: faq_answer and checkout_info.'''},\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {state['question']}\"}\n",
    "    ]\n",
    "\n",
    "    # Call the OpenAI model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=message_to_llm,\n",
    "        temperature=0.2,   # keep it deterministic for classification\n",
    "        max_tokens=150,\n",
    "    )\n",
    "\n",
    "    print (response)\n",
    "    # Extract the content from the response\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    # Ideally, parse as JSON â€” here assuming model returns a dict-like string\n",
    "    try:\n",
    "        import json\n",
    "        parsed = json.loads(answer)\n",
    "        return {\n",
    "            \"faq_answer\": parsed.get(\"faq_answer\", \"\"),\n",
    "            \"checkout_info\": parsed.get(\"checkout_info\", \"\")\n",
    "        }\n",
    "    except Exception:\n",
    "        # fallback if LLM gives plain text\n",
    "        return {\"faq_answer\": answer, \"checkout_info\": \"\"}\n",
    "\n",
    "\n",
    "@traceable(name=\"FAQAgent\")\n",
    "def FAQAgent(state: LibraryState):\n",
    "    print(\"FAQAgent ran\")\n",
    "    print(f\"FAQAgent state\", state)\n",
    "    if not state.get(\"faq_answer\"):\n",
    "        return {\"faq_answer\": \"Default FAQ: Library rules apply\"}\n",
    "    return {}\n",
    "\n",
    "@traceable(name=\"CheckoutAgent\")\n",
    "def CheckoutAgent(state: LibraryState):\n",
    "    print(\"CheckoutAgent ran\")\n",
    "    if not state.get(\"checkout_info\"):\n",
    "        return {\"checkout_info\": \"Checkout info: Not requested\"}\n",
    "    return {}\n",
    "\n",
    "@traceable(name=\"ResponseAgent\")\n",
    "def ResponseAgent(state: LibraryState):\n",
    "    print(\"ResponseAgent ran\")\n",
    "    final = f\"Q: {state['question']}\\n\"\n",
    "    if state.get(\"faq_answer\"):\n",
    "        final += f\"FAQ: {state['faq_answer']}\\n\"\n",
    "    if state.get(\"checkout_info\"):\n",
    "        final += f\"Checkout: {state['checkout_info']}\"\n",
    "    return {\"final_answer\": final}\n",
    "\n",
    "\n",
    "# --- Build the Graph ---\n",
    "builder = StateGraph(LibraryState)\n",
    "builder.add_node(\"ClassifierAgent\", ClassifierAgent)\n",
    "builder.add_node(\"FAQAgent\", FAQAgent)\n",
    "builder.add_node(\"CheckoutAgent\", CheckoutAgent)\n",
    "builder.add_node(\"ResponseAgent\", ResponseAgent)\n",
    "\n",
    "builder.add_edge(START, \"ClassifierAgent\")\n",
    "builder.add_edge(\"ClassifierAgent\", \"FAQAgent\")\n",
    "builder.add_edge(\"ClassifierAgent\", \"CheckoutAgent\")\n",
    "builder.add_edge(\"FAQAgent\", \"ResponseAgent\")\n",
    "builder.add_edge(\"CheckoutAgent\", \"ResponseAgent\")\n",
    "builder.add_edge(\"ResponseAgent\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45969394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               +-----------+              \n",
      "               | __start__ |              \n",
      "               +-----------+              \n",
      "                     *                    \n",
      "                     *                    \n",
      "                     *                    \n",
      "            +-----------------+           \n",
      "            | ClassifierAgent |           \n",
      "            +-----------------+           \n",
      "              ***          **             \n",
      "             *               **           \n",
      "           **                  **         \n",
      "+---------------+           +----------+  \n",
      "| CheckoutAgent |           | FAQAgent |  \n",
      "+---------------+           +----------+  \n",
      "              ***          **             \n",
      "                 *       **               \n",
      "                  **   **                 \n",
      "             +---------------+            \n",
      "             | ResponseAgent |            \n",
      "             +---------------+            \n",
      "                     *                    \n",
      "                     *                    \n",
      "                     *                    \n",
      "                +---------+               \n",
      "                | __end__ |               \n",
      "                +---------+               \n",
      "Graph saved as agentic_ai_library.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Visualize ---\n",
    "print(graph.get_graph().draw_ascii())\n",
    "graph.get_graph().draw_png(\"images/agentic_ai_library.png\")\n",
    "print(\"Graph saved as agentic_ai_library.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34d8aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierAgent ran\n",
      "state: {'question': 'When does library open?'}\n",
      "ChatCompletion(id='chatcmpl-CCopu8YEORMl89z83OH9XytjmhHRS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"faq_answer\": \"The library opens at 9:00 AM from Monday to Saturday and is closed on Sundays.\",\\n  \"checkout_info\": null\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757171386, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_7c233bf9d1', usage=CompletionUsage(completion_tokens=34, prompt_tokens=58, total_tokens=92, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "CheckoutAgent ran\n",
      "FAQAgent ran\n",
      "FAQAgent state {'question': 'When does library open?', 'faq_answer': 'The library opens at 9:00 AM from Monday to Saturday and is closed on Sundays.', 'checkout_info': None}\n",
      "ResponseAgent ran\n",
      "\n",
      "--- Final Answer ---\n",
      "Q: When does library open?\n",
      "FAQ: The library opens at 9:00 AM from Monday to Saturday and is closed on Sundays.\n",
      "Checkout: Checkout info: Not requested\n"
     ]
    }
   ],
   "source": [
    "# --- Run ---\n",
    "result = graph.invoke({\"question\": \"When does library open?\"})\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(result[\"final_answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b69c506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierAgent ran\n",
      "state: {'question': 'Is The Hobbit available?'}\n",
      "ChatCompletion(id='chatcmpl-CCopujrEfkACVLzEnOtTM8ONHMSva', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"faq_answer\": null,\\n  \"checkout_info\": \"The Hobbit is available for checkout. Would you like to reserve it or get more details?\"\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757171386, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_04d3664870', usage=CompletionUsage(completion_tokens=33, prompt_tokens=58, total_tokens=91, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "CheckoutAgent ran\n",
      "FAQAgent ran\n",
      "FAQAgent state {'question': 'Is The Hobbit available?', 'faq_answer': None, 'checkout_info': 'The Hobbit is available for checkout. Would you like to reserve it or get more details?'}\n",
      "ResponseAgent ran\n",
      "\n",
      "--- Final Answer ---\n",
      "Q: Is The Hobbit available?\n",
      "FAQ: Default FAQ: Library rules apply\n",
      "Checkout: The Hobbit is available for checkout. Would you like to reserve it or get more details?\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"Is The Hobbit available?\"})\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(result[\"final_answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa647a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
