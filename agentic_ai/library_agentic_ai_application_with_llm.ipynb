{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95de6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key is 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\n",
      "ClassifierAgent ran\n",
      "state: {'question': 'When does library open?'}\n",
      "ChatCompletion(id='chatcmpl-CDDvZtnKdyfrPf68CYuGjgNB5FVvL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"faq_answer\": \"The library opens at 9 AM and closes at 8 PM from Monday to Saturday, and is closed on Sundays.\",\\n  \"checkout_info\": null\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757267837, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_7c233bf9d1', usage=CompletionUsage(completion_tokens=39, prompt_tokens=60, total_tokens=99, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Raw response: {\n",
      "  \"faq_answer\": \"The library opens at 9 AM and closes at 8 PM from Monday to Saturday, and is closed on Sundays.\",\n",
      "  \"checkout_info\": null\n",
      "}\n",
      "Parsed response: {'faq_answer': 'The library opens at 9 AM and closes at 8 PM from Monday to Saturday, and is closed on Sundays.', 'checkout_info': None}\n",
      "FAQAgent ran\n",
      "FAQAgent state {'question': 'When does library open?', 'faq_answer': 'The library opens at 9 AM and closes at 8 PM from Monday to Saturday, and is closed on Sundays.', 'checkout_info': None}\n",
      "CheckoutAgent ran\n",
      "ResponseAgent ran\n",
      "ChatCompletion(id='chatcmpl-CDDvaq2Y6p5ZxBDU3hEm009CyXVEL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='At nine in the morning, the doors swing wide,  \\nFrom Monday through Saturday, with doors open with pride.  \\nBy eight in the evening, they close for the day,  \\nOn Sundays they’re closed — it’s always their way.  \\nSo come in the morning, don’t wait till late,  \\nEnjoy your visit, it’s never too late!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757267838, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_7c233bf9d1', usage=CompletionUsage(completion_tokens=73, prompt_tokens=86, total_tokens=159, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "\n",
      "--- Final Answer ---\n",
      "At nine in the morning, the doors swing wide,  \n",
      "From Monday through Saturday, with doors open with pride.  \n",
      "By eight in the evening, they close for the day,  \n",
      "On Sundays they’re closed — it’s always their way.  \n",
      "So come in the morning, don’t wait till late,  \n",
      "Enjoy your visit, it’s never too late!\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print (f'Key is {my_api_key}')\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=my_api_key)\n",
    "\n",
    "\n",
    "# --- Shared State ---\n",
    "class LibraryState(TypedDict):\n",
    "    question: Optional[str]\n",
    "    faq_answer: Optional[str]\n",
    "    checkout_info: Optional[str]\n",
    "    final_answer: Optional[str]\n",
    "\n",
    "\n",
    "def ClassifierAgent(state: LibraryState):\n",
    "    print(\"ClassifierAgent ran\")\n",
    "    print(f\"state: {state}\")\n",
    "\n",
    "    # Build the LLM messages\n",
    "    message_to_llm = [\n",
    "        {\"role\": \"system\", \"content\": '''You are a classifier agent in a library system. \n",
    "        Decide if the user is asking about book availability/checkout or about library FAQs. \n",
    "        Reply with JSON containing keys: faq_answer and checkout_info.'''},\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {state['question']}\"}\n",
    "    ]\n",
    "\n",
    "    # Call the OpenAI model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=message_to_llm,\n",
    "        # temperature=0.2,   # keep it deterministic for classification\n",
    "        # max_tokens=150,\n",
    "    )\n",
    "\n",
    "    print (response)\n",
    "    # Extract the content from the response\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    # Ideally, parse as JSON — here assuming model returns a dict-like string\n",
    "    try:\n",
    "        import json\n",
    "        parsed = json.loads(answer)\n",
    "        print(f\"Raw response: {answer}\")\n",
    "        print(f\"Parsed response: {parsed}\")\n",
    "\n",
    "        return {\n",
    "            \"faq_answer\": parsed.get(\"faq_answer\", \"\"),\n",
    "            \"checkout_info\": parsed.get(\"checkout_info\", \"\")\n",
    "        }\n",
    "    except Exception:\n",
    "        # fallback if LLM gives plain text\n",
    "        return {\"faq_answer\": answer, \"checkout_info\": \"\"}\n",
    "\n",
    "\n",
    "\n",
    "def FAQAgent(state: LibraryState):\n",
    "    print(\"FAQAgent ran\")\n",
    "    print(f\"FAQAgent state\", state)\n",
    "    if not state.get(\"faq_answer\"):\n",
    "        return {\"faq_answer\": \"Default FAQ: Library rules apply\"}\n",
    "    return {\"faq_answer\": state[\"faq_answer\"]}\n",
    "\n",
    "\n",
    "def CheckoutAgent(state: LibraryState):\n",
    "    print(\"CheckoutAgent ran\")\n",
    "    if not state.get(\"checkout_info\"):\n",
    "        return {\"checkout_info\": \"Checkout info: Not requested\"}\n",
    "    return { \"checkout_info\": state[\"checkout_info\"]}\n",
    "\n",
    "\n",
    "def ResponseAgent(state: LibraryState):\n",
    "    print(\"ResponseAgent ran\")\n",
    "  \n",
    "    message_to_llm = [\n",
    "        {\"role\": \"system\", \"content\": '''You are a response builder for the library application.\n",
    "          Please combine the FAQ answer and checkout info into a coherent response to the user's question.\n",
    "         Return as a poem'''},\n",
    "        {\"role\": \"user\", \"content\": f\"FAQ: {state['faq_answer']}\\nCheckout Info: {state['checkout_info']}\\nQuestion: {state['question']}\"}\n",
    "    ]\n",
    "\n",
    "    # Call the OpenAI model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=message_to_llm,\n",
    "        # temperature=0.2,   # keep it deterministic for classification\n",
    "        # max_tokens=150,\n",
    "    )\n",
    "\n",
    "    print (response)\n",
    "    # Extract the content from the response\n",
    "    final_answer = response.choices[0].message.content\n",
    "\n",
    "\n",
    "    return {\"final_answer\": final_answer}\n",
    "\n",
    "\n",
    "# --- Build the Graph ---\n",
    "builder = StateGraph(LibraryState)\n",
    "builder.add_node(\"ClassifierAgent\", ClassifierAgent)\n",
    "builder.add_node(\"FAQAgent\", FAQAgent)\n",
    "builder.add_node(\"CheckoutAgent\", CheckoutAgent)\n",
    "builder.add_node(\"ResponseAgent\", ResponseAgent)\n",
    "\n",
    "builder.add_edge(START, \"ClassifierAgent\")\n",
    "builder.add_edge(\"ClassifierAgent\", \"FAQAgent\")\n",
    "builder.add_edge(\"ClassifierAgent\", \"CheckoutAgent\")\n",
    "builder.add_edge(\"FAQAgent\", \"ResponseAgent\")\n",
    "builder.add_edge(\"CheckoutAgent\", \"ResponseAgent\")\n",
    "builder.add_edge(\"ResponseAgent\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "result = graph.invoke({\"question\": \"When does library open?\"})\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(result[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45969394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # --- Visualize ---\n",
    "# print(graph.get_graph().draw_ascii())\n",
    "# graph.get_graph().draw_png(\"images/agentic_ai_library.png\")\n",
    "# print(\"Graph saved as agentic_ai_library.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34d8aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierAgent ran\n",
      "state: {'question': 'When does library open?'}\n",
      "ChatCompletion(id='chatcmpl-CDDw5hU1p1SMaV3rapBjn6VpnU4p5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"faq_answer\": \"The library opens at 9:00 AM and closes at 5:00 PM from Monday to Saturday. It is closed on Sundays.\", \"checkout_info\": null}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757267869, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_7c233bf9d1', usage=CompletionUsage(completion_tokens=39, prompt_tokens=60, total_tokens=99, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Raw response: {\"faq_answer\": \"The library opens at 9:00 AM and closes at 5:00 PM from Monday to Saturday. It is closed on Sundays.\", \"checkout_info\": null}\n",
      "Parsed response: {'faq_answer': 'The library opens at 9:00 AM and closes at 5:00 PM from Monday to Saturday. It is closed on Sundays.', 'checkout_info': None}\n",
      "CheckoutAgent ran\n",
      "FAQAgent ran\n",
      "FAQAgent state {'question': 'When does library open?', 'faq_answer': 'The library opens at 9:00 AM and closes at 5:00 PM from Monday to Saturday. It is closed on Sundays.', 'checkout_info': None}\n",
      "ResponseAgent ran\n",
      "ChatCompletion(id='chatcmpl-CDDw6j8UB1p0krGxL3tugW2ZsEp48', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"At nine o'clock each Monday morn,  \\nThe library opens, welcoming, warm.  \\nTuesday through Saturday, same time here,  \\nFive pm closes, then it’s time to clear.  \\n\\nOn Sundays, silence holds the door,  \\nClosed, the library waits once more.  \\nNo checkout info requested, true,  \\nJust know these hours are clear for you.  \\n\\nSo plan your visit from nine to five,  \\nAnd read or study, thrive, and thrive.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757267870, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_7c233bf9d1', usage=CompletionUsage(completion_tokens=95, prompt_tokens=90, total_tokens=185, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "\n",
      "--- Final Answer ---\n",
      "At nine o'clock each Monday morn,  \n",
      "The library opens, welcoming, warm.  \n",
      "Tuesday through Saturday, same time here,  \n",
      "Five pm closes, then it’s time to clear.  \n",
      "\n",
      "On Sundays, silence holds the door,  \n",
      "Closed, the library waits once more.  \n",
      "No checkout info requested, true,  \n",
      "Just know these hours are clear for you.  \n",
      "\n",
      "So plan your visit from nine to five,  \n",
      "And read or study, thrive, and thrive.\n"
     ]
    }
   ],
   "source": [
    "# --- Run ---\n",
    "result = graph.invoke({\"question\": \"When does library open?\"})\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(result[\"final_answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b69c506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierAgent ran\n",
      "state: {'question': 'Is The Hobbit available?'}\n",
      "ChatCompletion(id='chatcmpl-CDDwDyrvTkY8mrGyjeHj5bph25qOZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"faq_answer\": null,\\n  \"checkout_info\": \"The Hobbit is available for checkout. Please visit the library or check online to reserve a copy.\"\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757267877, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_04d3664870', usage=CompletionUsage(completion_tokens=34, prompt_tokens=60, total_tokens=94, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Raw response: {\n",
      "  \"faq_answer\": null,\n",
      "  \"checkout_info\": \"The Hobbit is available for checkout. Please visit the library or check online to reserve a copy.\"\n",
      "}\n",
      "Parsed response: {'faq_answer': None, 'checkout_info': 'The Hobbit is available for checkout. Please visit the library or check online to reserve a copy.'}\n",
      "CheckoutAgent ran\n",
      "FAQAgent ran\n",
      "FAQAgent state {'question': 'Is The Hobbit available?', 'faq_answer': None, 'checkout_info': 'The Hobbit is available for checkout. Please visit the library or check online to reserve a copy.'}\n",
      "ResponseAgent ran\n",
      "ChatCompletion(id='chatcmpl-CDDwEKB0N5f1IGycvb2lWOFNAWs4P', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Yes, The Hobbit can be yours today,  \\nIt’s available for checkout without delay.  \\nVisit the library or go online with ease,  \\nReserve your copy, then settle in to read the stories that please.  \\n  \\nRemember, library rules apply—  \\nRespect the lending process, don't let good stories pass by.  \\nSo, come and borrow with joy and cheer,  \\nYour adventure in Middle-earth awaits right here!\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757267878, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_7c233bf9d1', usage=CompletionUsage(completion_tokens=84, prompt_tokens=82, total_tokens=166, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "\n",
      "--- Final Answer ---\n",
      "Yes, The Hobbit can be yours today,  \n",
      "It’s available for checkout without delay.  \n",
      "Visit the library or go online with ease,  \n",
      "Reserve your copy, then settle in to read the stories that please.  \n",
      "  \n",
      "Remember, library rules apply—  \n",
      "Respect the lending process, don't let good stories pass by.  \n",
      "So, come and borrow with joy and cheer,  \n",
      "Your adventure in Middle-earth awaits right here!\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"Is The Hobbit available?\"})\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(result[\"final_answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa647a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
